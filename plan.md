# MCP Code Execution - Python Port Plan

## Overview

This document outlines the plan to port the core MCP Code Execution runtime from TypeScript to Python 3.11+. The goal is to maintain the breakthrough 98.7% token reduction pattern while leveraging Python's strengths.

**Branch Strategy**: The Python port lives on the `python-port` branch. The TypeScript implementation will be **replaced** once the Python port is complete and validated. TypeScript code is kept temporarily only as reference during the port, then will be removed.

## Design Decisions

| Aspect | Choice | Rationale |
|--------|--------|-----------|
| **Python Version** | 3.11+ | Modern type hints (`\|` syntax), better performance, pattern matching |
| **Type System** | Pydantic models | Full validation, JSON serialization, excellent IDE support |
| **Async Framework** | asyncio + aiofiles | Native async/await, matches TypeScript's async patterns |
| **Path Handling** | pathlib.Path | More Pythonic than string paths |
| **Code Generation** | f-strings + templates | Simple, readable, no external template engine needed |
| **Package Manager** | uv | Modern, fast Python package manager (replaces pip/poetry) |
| **Package Structure** | src/ layout | Python best practice: `src/runtime/`, `src/servers/`, separate from tests |
| **Project Config** | pyproject.toml | Modern Python standard (PEP 518), used by uv |

## Architecture Mapping

### TypeScript → Python File Mapping

```
TypeScript (master branch)     Python (python-port branch)
runtime/mcp-client.ts      →   src/runtime/mcp_client.py
runtime/harness.ts         →   src/runtime/harness.py
runtime/generate-wrappers.ts → src/runtime/generate_wrappers.py
runtime/discover-schemas.ts  → src/runtime/discover_schemas.py
runtime/normalize-fields.ts  → src/runtime/normalize_fields.py
```

### Python Package Structure (src/ Layout)

```
mcp-code-execution/ (python-port branch)
├── src/                             # All Python source code
│   ├── runtime/                     # Core runtime package
│   │   ├── __init__.py              # Export public API
│   │   ├── mcp_client.py            # McpClientManager class
│   │   ├── harness.py               # CLI entry point
│   │   ├── generate_wrappers.py     # Wrapper generation
│   │   ├── discover_schemas.py      # Schema discovery
│   │   ├── normalize_fields.py      # Field normalization
│   │   └── schema_utils.py          # JSON Schema → Pydantic utilities
│   └── servers/                     # Generated wrappers (gitignored)
│       ├── __init__.py
│       └── {server_name}/
│           ├── __init__.py
│           ├── {tool_name}.py       # One file per tool
│           ├── discovered_types.py  # Discovered Pydantic models
│           └── utils.py             # Custom server utilities
├── tests/                           # Test files (pytest)
│   ├── __init__.py
│   ├── test_mcp_client.py
│   ├── test_generate_wrappers.py
│   └── integration/
│       └── test_filesystem.py
├── workspace/                       # User scripts (outside src/)
│   └── example_progressive_disclosure.py
├── mcp_config.json                  # MCP server configuration
├── discovery_config.json            # Schema discovery config
├── pyproject.toml                   # Python project config (uv)
├── uv.lock                          # Lock file (auto-generated by uv)
├── .python-version                  # Python version (3.11+)
├── README.md                        # Updated for Python
└── plan.md                          # This document

Note: TypeScript files (runtime/, tests/*.ts) will be removed from python-port branch
```

## Implementation Phases

### Phase 0: Proof of Concept (NEW - CRITICAL)

**Goal**: Validate Python MCP SDK compatibility before committing to architecture

**Why Critical**: The entire architecture depends on the Python MCP SDK supporting stdio transport and having compatible behavior with the TypeScript SDK. We must validate this before implementing.

**Tasks**:

1. **Create minimal PoC script**:
   ```python
   # poc_mcp_test.py - Validate Python MCP SDK
   import asyncio
   from mcp import Client
   from mcp.client.stdio import StdioServerParameters, stdio_client

   async def test_mcp_connection():
       """Test connecting to git MCP server"""
       server_params = StdioServerParameters(
           command="npx",
           args=["-y", "@modelcontextprotocol/server-git"]
       )

       async with stdio_client(server_params) as (read, write):
           async with Client(read, write) as client:
               # Initialize
               await client.initialize()

               # List tools
               tools = await client.list_tools()
               print(f"✓ Found {len(tools.tools)} tools")
               for tool in tools.tools:
                   print(f"  - {tool.name}: {tool.description}")

               # Test calling a tool
               result = await client.call_tool(
                   name="git_status",
                   arguments={"repo_path": "."}
               )

               print(f"\n✓ Result type: {type(result)}")
               print(f"✓ Result structure: {result}")

               # Validate response unwrapping
               if hasattr(result, 'content'):
                   print(f"✓ Has .content attribute")
                   if isinstance(result.content, list):
                       print(f"✓ Content is list with {len(result.content)} items")

   if __name__ == "__main__":
       asyncio.run(test_mcp_connection())
   ```

2. **Test with both git and fetch servers**:
   - git: `@modelcontextprotocol/server-git`
   - fetch: `@modelcontextprotocol/server-fetch`

3. **Validate**:
   - ✅ stdio transport works
   - ✅ Connection lifecycle (connect, initialize, call, close)
   - ✅ Response structure matches TypeScript expectations
   - ✅ List tools returns expected format
   - ✅ Tool calling works with arguments

**Deliverables**:
- ✅ Working PoC script that connects to git and fetch servers
- ✅ Documentation of any differences from TypeScript SDK
- ✅ Validated response unwrapping patterns

**Go/No-Go Decision**: If this PoC fails or reveals major incompatibilities, the architecture may need revision. Only proceed to Phase 1 after PoC succeeds.

---

### Phase 1: Project Setup & Structure

**Goal**: Set up a complete Python project with modern tooling (uv + src/ layout)

**Tasks**:

1. **Clean up TypeScript files** (python-port branch):
   - Keep TypeScript files temporarily as reference during port
   - Mark them clearly (e.g., move to `_typescript_reference/`)
   - Will remove completely after Python port is validated
   - Keep `mcp-config.example.json`, `discovery-config.example.json`

2. **Initialize uv project**:
   ```bash
   uv init --lib --name mcp-execution
   uv python pin 3.11
   ```

3. **Create `pyproject.toml`** with uv configuration:
   ```toml
   [project]
   name = "mcp-execution"
   version = "0.1.0"
   description = "Progressive tool discovery pattern for MCP (98.7% token reduction)"
   requires-python = ">=3.11"
   dependencies = [
       "mcp>=1.0.0",
       "pydantic>=2.0.0",
       "aiofiles>=23.0.0",
   ]

   [project.optional-dependencies]
   dev = [
       "black>=24.0.0",
       "mypy>=1.8.0",
       "ruff>=0.2.0",
       "pytest>=8.0.0",
       "pytest-asyncio>=0.23.0",
   ]

   [build-system]
   requires = ["hatchling"]
   build-backend = "hatchling.build"

   [tool.black]
   line-length = 100

   [tool.mypy]
   strict = true
   python_version = "3.11"

   [tool.ruff]
   line-length = 100
   target-version = "py311"
   ```

4. **Update `.gitignore`** for Python:
   ```gitignore
   # Python
   __pycache__/
   *.py[cod]
   *$py.class
   .pytest_cache/
   .mypy_cache/
   .ruff_cache/
   *.egg-info/
   dist/
   build/
   .uv/

   # Generated servers (keep this)
   servers/

   # Virtual environments
   .venv/
   venv/
   ```

5. **Create src/ structure**:
   ```bash
   mkdir -p src/runtime src/servers tests/unit tests/integration workspace
   touch src/runtime/__init__.py
   touch src/servers/__init__.py
   touch tests/__init__.py
   ```

6. **Create error handling infrastructure**:
   ```python
   # src/runtime/exceptions.py
   """Custom exceptions for MCP execution"""

   class McpExecutionError(Exception):
       """Base exception for MCP execution errors"""
       pass

   class ServerConnectionError(McpExecutionError):
       """Failed to connect to MCP server"""
       pass

   class ToolNotFoundError(McpExecutionError):
       """Tool not found on server"""
       pass

   class ToolExecutionError(McpExecutionError):
       """Tool execution failed"""
       pass

   class ConfigurationError(McpExecutionError):
       """Invalid configuration"""
       pass

   class SchemaValidationError(McpExecutionError):
       """Schema validation failed"""
       pass
   ```

7. **Create config validation with Pydantic**:
   ```python
   # src/runtime/config.py
   """Configuration models for MCP servers"""
   from pydantic import BaseModel, Field
   from typing import Dict

   class ServerConfig(BaseModel):
       """Configuration for a single MCP server"""
       command: str
       args: list[str]
       env: dict[str, str] | None = None

   class McpConfig(BaseModel):
       """Root configuration for all MCP servers"""
       mcpServers: dict[str, ServerConfig] = Field(alias="mcpServers")

       class Config:
           populate_by_name = True
   ```

8. **Install dependencies**:
   ```bash
   # Install all dependencies including dev extras
   uv sync --all-extras

   # Or install in editable mode with dev dependencies
   uv pip install -e ".[dev]"
   ```

**Deliverables**:
- ✅ TypeScript files moved to `_typescript_reference/`
- ✅ `pyproject.toml` (uv-compatible)
- ✅ `.python-version` (3.11)
- ✅ Updated `.gitignore`
- ✅ `src/` structure with packages
- ✅ `src/runtime/exceptions.py` (error hierarchy)
- ✅ `src/runtime/config.py` (Pydantic config models)
- ✅ `uv.lock` generated
- ✅ Dependencies installed

---

### Phase 2: Core Runtime - MCP Client Manager

**File**: `src/runtime/mcp_client.py`

**Goal**: Port the lazy-loading MCP client manager (the heart of the 98.7% token reduction)

**Key Components**:

```python
import logging
from pathlib import Path
from functools import lru_cache
from mcp import Client
from mcp.client.stdio import StdioServerParameters, stdio_client
from .config import McpConfig, ServerConfig
from .exceptions import ServerConnectionError, ConfigurationError, ToolNotFoundError

logger = logging.getLogger("mcp_execution.client")

class McpClientManager:
    """Lazy-loading MCP client manager"""

    def __init__(self):
        self._clients: Dict[str, Client] = {}
        self._tool_cache: Dict[str, List[Tool]] = {}
        self._config: Optional[McpConfig] = None
        self._initialized: bool = False

    async def initialize(self, config_path: Path | None = None) -> None:
        """Load config only - don't connect to servers yet"""
        config_file = config_path or Path.cwd() / "mcp_config.json"

        if not config_file.exists():
            raise ConfigurationError(f"Config file not found: {config_file}")

        try:
            import aiofiles
            async with aiofiles.open(config_file) as f:
                content = await f.read()
            self._config = McpConfig.model_validate_json(content)
            logger.info(f"Configuration loaded ({len(self._config.mcpServers)} servers available)")
        except Exception as e:
            raise ConfigurationError(f"Failed to load config: {e}")

    async def _connect_to_server(
        self,
        server_name: str,
        config: ServerConfig
    ) -> None:
        """Connect to a single server on-demand"""
        ...

    async def call_tool(
        self,
        tool_identifier: str,
        params: Dict[str, Any]
    ) -> Any:
        """
        Call tool with lazy connection
        Format: "serverName__toolName"
        """
        ...

    async def list_all_tools(self) -> List[Tool]:
        """List all available tools (connects to all servers)"""
        ...

    async def cleanup(self) -> None:
        """Close all connections gracefully"""
        ...

# Singleton pattern (thread-safe with lru_cache)
@lru_cache(maxsize=1)
def get_mcp_client_manager() -> McpClientManager:
    """Get or create singleton instance"""
    return McpClientManager()

async def call_mcp_tool(tool_identifier: str, params: Dict[str, Any]) -> Any:
    """Convenience function for calling tools"""
    ...
```

**Key Features to Preserve**:
- ✅ Lazy initialization (config loaded, servers NOT connected)
- ✅ Lazy connection (servers connect on first tool call)
- ✅ Tool caching (avoid repeated list_tools calls)
- ✅ Defensive unwrapping (`response.value or response`)
- ✅ JSON parsing for text responses
- ✅ Clear error messages with context
- ✅ Singleton pattern
- ✅ Proper cleanup/shutdown

**Dependencies**:
- `mcp` (official Python MCP SDK)
- `aiofiles` (async file I/O)
- `pathlib` (path handling)
- Standard library: `json`, `asyncio`, `typing`

**Testing**:
- Load config without connecting
- Connect on first tool call
- Verify tool caching works
- Test cleanup/shutdown

**Deliverables**:
- ✅ `src/runtime/mcp_client.py`
- ✅ `tests/test_mcp_client.py` (unit tests for lazy loading)

---

### Phase 3: Script Execution Harness

**File**: `src/runtime/harness.py`

**Goal**: CLI entry point for executing Python scripts with MCP support

**Key Components**:

```python
import logging
import signal
import sys
from pathlib import Path
import runpy

from .mcp_client import get_mcp_client_manager
from .exceptions import McpExecutionError

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format="[%(levelname)s] %(message)s",
    stream=sys.stderr
)

logger = logging.getLogger("mcp_execution.harness")

async def main() -> None:
    """Main entry point for script execution"""

    # 1. Parse CLI arguments (script path)
    if len(sys.argv) < 2:
        logger.error("Usage: python -m runtime.harness <script_path>")
        sys.exit(1)

    script_path = Path(sys.argv[1]).resolve()

    # 2. Validate script exists
    if not script_path.exists():
        logger.error(f"Script not found: {script_path}")
        sys.exit(1)

    # 3. Add src/ to Python path for imports
    src_path = Path(__file__).parent.parent
    if str(src_path) not in sys.path:
        sys.path.insert(0, str(src_path))

    # 4. Initialize MCP client manager
    manager = get_mcp_client_manager()
    try:
        await manager.initialize()
    except McpExecutionError as e:
        logger.error(f"Failed to initialize MCP client: {e}")
        sys.exit(1)

    # 5. Set up signal handling (CORRECT async approach)
    shutdown_event = asyncio.Event()

    def signal_handler(signum, frame):
        logger.info(f"Received signal {signum}, shutting down...")
        shutdown_event.set()

    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)

    # 6. Execute the script using runpy (simpler than importlib)
    exit_code = 0
    try:
        # Check if shutdown was requested
        if shutdown_event.is_set():
            logger.info("Shutdown requested before execution")
            return

        # Execute script in isolated namespace
        logger.info(f"Executing script: {script_path}")
        runpy.run_path(str(script_path), run_name="__main__")

    except KeyboardInterrupt:
        logger.info("Execution interrupted by user")
        exit_code = 130  # Standard exit code for Ctrl+C
    except Exception as e:
        logger.error(f"Script execution failed: {e}", exc_info=True)
        exit_code = 1
    finally:
        # 7. Cleanup
        logger.debug("Cleaning up MCP connections...")
        try:
            await manager.cleanup()
        except Exception as e:
            logger.error(f"Cleanup failed: {e}", exc_info=True)
            exit_code = 1

        sys.exit(exit_code)

if __name__ == "__main__":
    asyncio.run(main())
```

**Key Features (IMPLEMENTED ABOVE)**:
- ✅ CLI argument parsing
- ✅ Script path validation
- ✅ MCP client initialization
- ✅ Signal handlers (SIGINT/SIGTERM) - FIXED async approach
- ✅ Script execution with `runpy` (isolated namespace)
- ✅ sys.path management for imports
- ✅ Logging infrastructure
- ✅ Proper cleanup with error handling
- ✅ Standard exit codes

**Testing**:
- Execute simple test script
- Verify cleanup on Ctrl+C
- Test error handling

**Deliverables**:
- ✅ `src/runtime/harness.py`
- ✅ Can be invoked as `uv run python -m runtime.harness workspace/script.py`
- ✅ Add script alias in `pyproject.toml`: `mcp-exec = "runtime.harness:main"`

---

### Phase 4: Field Normalization (MOVED UP - Required before Phase 5)

**File**: `src/runtime/normalize_fields.py`

**Goal**: Normalize inconsistent field casing from different APIs

**Why First**: Wrapper generation (Phase 5) integrates field normalization, so this must be implemented first.

See detailed implementation below in original Phase 6 section.

---

### Phase 5: Wrapper Generation

**File**: `src/runtime/generate_wrappers.py`

**Goal**: Generate typed Python wrappers from MCP server tool definitions

**Dependencies**: Phase 4 (Field Normalization) must be complete

**Key Components**:

1. **JSON Schema → Pydantic Converter**

```python
def json_schema_to_pydantic_field(
    schema: Dict[str, Any],
    field_name: str,
    required: bool
) -> Tuple[Type, Any]:
    """
    Convert JSON Schema to Pydantic field type

    Returns: (field_type, field_default)

    Examples:
    - {"type": "string"} → (str, ...)
    - {"type": "string"} (optional) → (Optional[str], None)
    - {"type": "array", "items": {"type": "string"}} → (List[str], ...)
    - {"type": ["string", "null"]} → (Optional[str], None)
    - {"enum": ["asc", "desc"]} → (Literal["asc", "desc"], ...)
    """
    ...

def generate_pydantic_model(
    tool_name: str,
    schema: Dict[str, Any]
) -> str:
    """Generate Pydantic model class from JSON Schema"""

    # Example output:
    # class SearchCodeParams(BaseModel):
    #     q: str
    #     order: Optional[Literal["asc", "desc"]] = None
    #     page: Optional[int] = None
    #     per_page: Optional[int] = None
    ...
```

2. **Wrapper Function Generator**

```python
def generate_tool_wrapper(
    server_name: str,
    tool: Tool
) -> str:
    """
    Generate Python wrapper function for a tool

    Output:
    ```python
    async def search_code(params: SearchCodeParams) -> SearchCodeResult:
        '''
        Search for code across GitHub repositories

        Args:
            params: Search parameters

        Returns:
            Search results
        '''
        from runtime.mcp_client import call_mcp_tool

        result = await call_mcp_tool(
            "github__search_code",
            params.model_dump()
        )

        # Defensive unwrapping
        data = getattr(result, 'value', result)

        return SearchCodeResult.model_validate(data)
    ```
    """
    ...
```

3. **Main Generator**

```python
async def generate_wrappers() -> None:
    """
    Main wrapper generation orchestrator

    1. Load mcp_config.json
    2. For each configured server:
       a. Connect to server
       b. Call list_tools()
       c. For each tool:
          - Generate Pydantic models (params + result)
          - Generate wrapper function
          - Write to servers/{server}/{tool}.py
       d. Generate servers/{server}/__init__.py
       e. Generate servers/{server}/README.md
    3. Generate servers/__init__.py
    """
    ...
```

**Key Features**:
- ✅ JSON Schema type mapping (string, number, boolean, array, object, enum, unions)
- ✅ Handle required vs optional fields
- ✅ Generate Pydantic models with validation
- ✅ Generate wrapper functions with type hints
- ✅ Defensive unwrapping in generated code
- ✅ Field normalization integration
- ✅ JSDoc → docstring conversion
- ✅ Barrel exports (`__init__.py`)
- ✅ Per-server README generation
- ✅ Preserve custom `utils.py` files

**Type Mapping**:

| JSON Schema | Python Type |
|-------------|-------------|
| `"string"` | `str` |
| `"number"` | `float` |
| `"integer"` | `int` |
| `"boolean"` | `bool` |
| `"null"` | `None` |
| `["string", "null"]` | `Optional[str]` |
| `{"type": "array", "items": T}` | `List[T]` |
| `{"type": "object", "properties": {...}}` | Nested Pydantic model |
| `{"type": "object", "additionalProperties": T}` | `Dict[str, T]` |
| `{"enum": ["a", "b"]}` | `Literal["a", "b"]` |

**CLI**:
- Invoke as: `uv run python -m runtime.generate_wrappers`
- Or add script in `pyproject.toml`: `mcp-generate = "runtime.generate_wrappers:main"`
- Or keep npm script: `npm run generate` (calls Python version for compatibility)

**Testing**:
- Test with **git server** (`@modelcontextprotocol/server-git`):
  - Generate wrappers for git_status, git_log, git_diff tools
  - Verify Pydantic models handle git-specific responses
- Test with **fetch server** (`@modelcontextprotocol/server-fetch`):
  - Generate wrappers for fetch tool
  - Verify URL validation in parameters
- Verify generated Pydantic models are valid (mypy check)
- Verify generated functions work with real servers

**Deliverables**:
- ✅ `src/runtime/generate_wrappers.py`
- ✅ `src/runtime/schema_utils.py` (JSON Schema utilities)
- ✅ Generated wrappers in `src/servers/`
- ✅ `tests/test_generate_wrappers.py` (unit tests)

---

### Phase 6: Schema Discovery

**File**: `src/runtime/discover_schemas.py`

**Goal**: Generate Pydantic models from actual API responses (for servers without output schemas)

**Key Components**:

```python
async def discover_schemas() -> None:
    """
    Schema discovery from real API responses

    1. Load discovery_config.json
    2. For each configured safe tool:
       a. Execute with sample parameters
       b. Capture response
       c. Unwrap .value if present
       d. Infer Pydantic model from response structure
       e. Make all fields optional (defensive)
       f. Write to servers/{server}/discovered_types.py
    """
    ...

def infer_pydantic_model_from_response(
    tool_name: str,
    response_data: Any
) -> str:
    """
    Infer Pydantic model from actual response

    Uses type introspection:
    - str → str
    - int → int
    - float → float
    - bool → bool
    - list → List[inferred_item_type]
    - dict → Nested Pydantic model
    - None → Optional

    All fields marked Optional by default (defensive)
    """
    ...
```

**Key Features**:
- ✅ Safe tool execution (read-only operations)
- ✅ Response capture and unwrapping
- ✅ Type inference from actual data
- ✅ Array handling (use first element as template)
- ✅ All fields optional (defensive coding)
- ✅ Metadata preservation (tool description, sample params)
- ✅ Warning comments about defensive coding

**Configuration**:
```json
{
  "servers": {
    "github": {
      "safeTools": {
        "search_code": {
          "q": "language:python MCP",
          "per_page": 1
        }
      }
    }
  }
}
```

**CLI**:
- Invoke as: `uv run python -m runtime.discover_schemas`
- Or add script in `pyproject.toml`: `mcp-discover = "runtime.discover_schemas:main"`
- Or keep npm script: `npm run discover-schemas` (compatibility)

**Testing**:
- Test with safe GitHub tool
- Verify generated types match response structure
- Verify all fields are optional

**Deliverables**:
- ✅ `src/runtime/discover_schemas.py`
- ✅ `discovery_config.example.json` (root level)
- ✅ Generated `src/servers/{server}/discovered_types.py`

---

### Phase 4 (Detailed): Field Normalization Implementation

**File**: `src/runtime/normalize_fields.py`

**Goal**: Normalize inconsistent field casing from different APIs

**Note**: This was moved up from original Phase 6 to Phase 4 because it's required by wrapper generation.

**Key Components**:

```python
from typing import Literal, Any, Dict, List, Optional
from pydantic import BaseModel

NormalizationStrategy = Literal["none", "ado-pascal-case"]

class NormalizationConfig(BaseModel):
    """Configuration for field normalization per server"""
    servers: Dict[str, NormalizationStrategy]

# Default configuration
NORMALIZATION_CONFIG = NormalizationConfig(
    servers={
        "ado": "ado-pascal-case",
        "filesystem": "none",
        "github": "none",
    }
)

def normalize_field_names(
    obj: Any,
    server_name: str
) -> Any:
    """
    Normalize field names based on server strategy

    Recursively traverses dicts and lists
    Returns new object (immutable)
    """
    strategy = NORMALIZATION_CONFIG.servers.get(server_name, "none")

    if strategy == "none":
        return obj
    elif strategy == "ado-pascal-case":
        return normalize_ado_fields(obj)
    else:
        return obj

def normalize_ado_fields(obj: Any) -> Any:
    """
    ADO-specific normalization

    Rules:
    - system.* → System.*
    - microsoft.* → Microsoft.*
    - custom.* → Custom.*
    - wef_* → WEF_*
    """
    if obj is None or isinstance(obj, (str, int, float, bool)):
        return obj

    if isinstance(obj, list):
        return [normalize_ado_fields(item) for item in obj]

    if isinstance(obj, dict):
        normalized = {}
        for key, value in obj.items():
            new_key = key

            if key.startswith("system."):
                new_key = "System." + key[7:]
            elif key.startswith("microsoft."):
                new_key = "Microsoft." + key[10:]
            elif key.startswith("custom."):
                new_key = "Custom." + key[7:]
            elif key.startswith("wef_"):
                new_key = "WEF_" + key[4:]

            normalized[new_key] = normalize_ado_fields(value)

        return normalized

    return obj
```

**Key Features**:
- ✅ Strategy pattern (pluggable normalization)
- ✅ Recursive traversal
- ✅ Immutability (returns new objects)
- ✅ Configuration-driven
- ✅ Type-safe with Pydantic

**Integration**:
- Called in `generate_wrappers.py` when generating tool wrappers
- Optionally called manually in user scripts

**Testing**:
- Test with ADO response structures
- Verify recursion works
- Verify immutability

**Deliverables**:
- ✅ `src/runtime/normalize_fields.py`
- ✅ `tests/test_normalize_fields.py` (unit tests)

---

### Phase 7: Integration Testing & Example Script

**Goal**: Validate end-to-end functionality with real MCP servers

**Test Servers**:
- **git** (`@modelcontextprotocol/server-git`): Test with local git repository
- **fetch** (`@modelcontextprotocol/server-fetch`): Test HTTP fetching

**Tasks**:

1. **Create integration tests** (`tests/integration/`):
   ```python
   # tests/integration/test_git_server.py
   import pytest
   from runtime.mcp_client import get_mcp_client_manager

   @pytest.mark.asyncio
   async def test_git_status():
       manager = get_mcp_client_manager()
       await manager.initialize()  # Uses mcp_config.json with git server

       result = await manager.call_tool(
           "git__git_status",
           {"repo_path": "."}
       )

       assert result is not None
       # Validate response structure

   # tests/integration/test_fetch_server.py
   @pytest.mark.asyncio
   async def test_fetch_url():
       manager = get_mcp_client_manager()
       await manager.initialize()

       result = await manager.call_tool(
           "fetch__fetch",
           {"url": "https://example.com"}
       )

       assert "content" in result
   ```

2. **Create example script** (`workspace/example_progressive_disclosure.py`):

**Port from**: `tests/example-progressive-disclosure.ts` (TypeScript version)

**Example**:

```python
"""
Example: Progressive Disclosure Pattern

Demonstrates the 98.7% token reduction pattern:
1. Agent explores ./servers/ to discover available tools
2. Agent reads only needed tool definitions
3. Agent writes and executes this script
4. Script processes data locally
5. Only summary returned to agent
"""

import asyncio
from pathlib import Path
from runtime.mcp_client import call_mcp_tool

async def main():
    """
    Find all TypeScript files in /private/tmp and count
    how many contain 'async'
    """

    # List directory
    result = await call_mcp_tool(
        "filesystem__list_directory",
        {"path": "/private/tmp"}
    )

    # Filter TypeScript files
    files = result.get("entries", [])
    ts_files = [f for f in files if f.endswith(".ts")]

    # Count files with 'async'
    async_count = 0
    for file in ts_files:
        content = await call_mcp_tool(
            "filesystem__read_file",
            {"path": f"/private/tmp/{file}"}
        )

        if "async" in content:
            async_count += 1

    # Return summary (NOT raw file contents)
    print({
        "total_ts_files": len(ts_files),
        "files_with_async": async_count,
        "percentage": f"{async_count / len(ts_files) * 100:.1f}%"
            if ts_files else "0%"
    })

if __name__ == "__main__":
    asyncio.run(main())
```

**Run with**:
```bash
uv run python -m runtime.harness workspace/example_progressive_disclosure.py
# Or with script alias:
uv run mcp-exec workspace/example_progressive_disclosure.py
```

**Key Features**:
- ✅ Uses generated wrappers (or call_mcp_tool directly)
- ✅ Processes data locally
- ✅ Returns only summary
- ✅ Demonstrates token efficiency

**Deliverables**:
- ✅ `workspace/example_progressive_disclosure.py`
- ✅ Verified working end-to-end with real MCP server

---

### Phase 8: Documentation & Polish

**Goal**: Complete Python-specific documentation

**Tasks**:

1. **Update README.md**:
   - Add Python installation section
   - Add Python quick start
   - Update examples to show Python usage
   - Document Python-specific patterns
   - Note both TypeScript and Python versions available

2. **Create Python-specific docs**:
   - `docs/python-port.md` - Differences from TypeScript version
   - `docs/pydantic-usage.md` - Using Pydantic models
   - `docs/type-safety.md` - Python type hints and mypy

3. **Add Python scripts to pyproject.toml**:
   ```toml
   [project.scripts]
   mcp-exec = "runtime.harness:main"
   mcp-generate = "runtime.generate_wrappers:main"
   mcp-discover = "runtime.discover_schemas:main"
   ```

4. **Update package.json** (for compatibility):
   ```json
   {
     "scripts": {
       "generate": "uv run python -m runtime.generate_wrappers",
       "discover-schemas": "uv run python -m runtime.discover_schemas",
       "exec": "uv run python -m runtime.harness"
     }
   }
   ```

5. **Development setup instructions**:
   ```bash
   # Install uv (if not installed)
   curl -LsSf https://astral.sh/uv/install.sh | sh

   # Install all dependencies including dev extras
   uv sync --all-extras

   # Run type checking
   uv run mypy src/

   # Format code
   uv run black src/ tests/

   # Lint
   uv run ruff check src/ tests/

   # Run tests
   uv run pytest
   ```

**Deliverables**:
- ✅ Updated README.md
- ✅ Python-specific documentation
- ✅ Development setup guide

---

## Dependencies

### Core Runtime Dependencies

```toml
[project]
dependencies = [
    "mcp>=1.0.0",           # Official Python MCP SDK
    "pydantic>=2.0.0",      # Type validation and serialization
    "aiofiles>=23.0.0",     # Async file I/O
    "click>=8.0.0",         # CLI framework (optional)
]
```

### Development Dependencies

```toml
[project.optional-dependencies]
dev = [
    "black>=24.0.0",        # Code formatting
    "mypy>=1.8.0",          # Type checking
    "ruff>=0.2.0",          # Fast linting
    "pytest>=8.0.0",        # Testing
    "pytest-asyncio>=0.23.0", # Async test support
]
```

## Testing Strategy

### Unit Tests (tests/)
- `test_mcp_client.py` - McpClientManager lazy loading
- `test_schema_utils.py` - JSON Schema conversion
- `test_normalize_fields.py` - Field normalization
- `test_generate_wrappers.py` - Code generation

### Integration Tests (tests/integration/)
- `test_filesystem_integration.py` - With real filesystem server
- `test_github_integration.py` - With real GitHub server
- `test_harness_integration.py` - Script execution

### Validation
- Run `uv run mypy src/` (strict mode)
- Run `uv run black --check src/ tests/` for formatting
- Run `uv run ruff check src/ tests/` for linting
- All tests passing with `uv run pytest`

## Success Criteria

✅ **Core Functionality**:
- [ ] MCP client manager implements lazy loading pattern
- [ ] Script harness executes Python scripts with MCP support
- [ ] Wrapper generation creates valid Pydantic models
- [ ] Schema discovery generates types from responses
- [ ] Field normalization works for configured servers

✅ **Type Safety**:
- [ ] All runtime code has complete type hints
- [ ] Generated wrappers are fully typed
- [ ] mypy passes in strict mode
- [ ] IDE autocomplete works for generated tools

✅ **Pattern Preservation**:
- [ ] Progressive disclosure pattern intact (98.7% token reduction)
- [ ] Lazy server connections work
- [ ] Tool caching prevents repeated calls
- [ ] Defensive unwrapping in all the right places

✅ **Documentation**:
- [ ] README updated with Python instructions
- [ ] Example script demonstrates the pattern
- [ ] Code is well-commented
- [ ] Development setup documented

✅ **Quality**:
- [ ] Code formatted with black
- [ ] Linting passes with ruff
- [ ] All tests passing
- [ ] No security issues (safe file handling)

## Timeline Estimate

Assuming focused development:

| Phase | Estimated Time | Priority |
|-------|---------------|----------|
| Phase 0: PoC | 2-3 hours | **P0-CRITICAL** |
| Phase 1: Project Setup | 2-3 hours | P0 |
| Phase 2: MCP Client | 4-6 hours | P0 |
| Phase 3: Harness | 2-3 hours | P0 |
| Phase 4: Normalization | 2 hours | P0 (moved up) |
| Phase 5: Wrapper Gen | 6-8 hours | P0 |
| Phase 6: Schema Discovery | 3-4 hours | P1 |
| Phase 7: Integration Tests + Example | 3-4 hours | P0 |
| Phase 8: Documentation | 2-3 hours | P0 |

**Total**: ~26-37 hours of focused development (includes PoC)

**Minimum Viable Port** (P0 only): ~21-30 hours

**Critical Path**: Phase 0 → Phase 1 → Phase 2 → Phase 3 → Phase 4 → Phase 5 → Phase 7 → Phase 8

## Risks & Mitigations

| Risk | Mitigation |
|------|------------|
| Python MCP SDK differences | Review SDK docs first, validate feature parity |
| Pydantic model generation complexity | Start with simple types, iterate |
| Async/await edge cases | Comprehensive testing, use asyncio best practices |
| Type hint limitations vs TypeScript | Use `typing.cast()` where needed, accept some Any types |
| Performance differences | Profile with real workloads, optimize if needed |

## Branch Workflow

### Current Status
- **master branch**: TypeScript implementation (will be replaced)
- **python-port branch**: Python implementation (this plan)

### Development Workflow

1. **All Python development happens on `python-port` branch**

2. **During port (TypeScript as reference)**:
   ```bash
   # Move TypeScript files to reference folder
   git mv runtime _typescript_reference/runtime
   git mv tests/*.ts _typescript_reference/tests/
   git commit -m "Move TypeScript files to reference folder during port"
   ```

3. **After Python port is validated and complete**:
   ```bash
   # Remove TypeScript reference
   git rm -rf _typescript_reference/
   git commit -m "Remove TypeScript implementation, Python port complete"

   # Merge python-port → master (Python becomes the main implementation)
   git checkout master
   git merge python-port
   ```

4. **Shared files** (update for Python):
   - `mcp-config.example.json` - Update for Python examples
   - `discovery-config.example.json` - Keep as-is
   - `AGENTS.md` - Update for Python
   - `.gitignore` - Extend for Python
   - `README.md` - Rewrite for Python (archive TypeScript README)

### Final State

After port is complete, master branch will contain only the Python implementation. The TypeScript version will live in git history if needed for reference.

## Future Enhancements

After initial port:
- [ ] Add CLI with `click` or `typer` for better UX
- [ ] Add progress indicators for wrapper generation
- [ ] Add watch mode for auto-regeneration
- [ ] Add Python-specific optimizations (connection pooling, etc.)
- [ ] Consider `fastapi` integration for HTTP server mode
- [ ] Add comprehensive error recovery
- [ ] Add logging with `structlog`
- [ ] Package for PyPI distribution
- [ ] Publish to PyPI as `mcp-execution`

## References

- [Official Python MCP SDK](https://github.com/modelcontextprotocol/python-sdk)
- [Pydantic Documentation](https://docs.pydantic.dev/)
- [Python Type Hints Cheat Sheet](https://mypy.readthedocs.io/en/stable/cheat_sheet_py3.html)
- [asyncio Best Practices](https://docs.python.org/3/library/asyncio-dev.html)
- Original TypeScript Implementation (this repository)

---

## Summary

This plan outlines a complete Python port of the MCP Code Execution runtime to the `python-port` branch, using:
- **uv** for modern Python package management
- **src/ layout** following Python best practices
- **Pydantic** for type-safe generated wrappers
- **Python 3.11+** for modern type hints and performance

The port preserves the breakthrough **98.7% token reduction** pattern while making the runtime more accessible to Python developers. The TypeScript implementation remains on `master`, allowing both communities to benefit.

**Next Steps**: Begin with Phase 1 (Project Setup) to establish the Python project structure.

---

**Document Version**: 3.0
**Last Updated**: 2025-11-07
**Status**: Ready for Implementation (Reviewed by Python Architect)
**Branch**: python-port

## Changes from v2.0:
- ✅ Added Phase 0 (PoC) to validate Python MCP SDK compatibility
- ✅ Fixed critical signal handling bug in harness (async context)
- ✅ Added error handling hierarchy (`src/runtime/exceptions.py`)
- ✅ Added Pydantic config validation (`src/runtime/config.py`)
- ✅ Added comprehensive logging strategy
- ✅ Reordered phases: Normalization (Phase 4) before Wrapper Generation (Phase 5)
- ✅ Updated to use `runpy` for script execution (simpler than importlib)
- ✅ Added sys.path management for imports
- ✅ Specified test servers: git and fetch from official MCP servers
- ✅ Clarified TypeScript will be replaced (not coexist)
- ✅ Added integration test examples
- ✅ Updated timeline to 26-37 hours (includes PoC)
